{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62b685c1-fe44-4f01-b9e3-5808cf10752f",
   "metadata": {},
   "source": [
    "# Chat With Your Data\n",
    "\n",
    "## Solution: Chat With Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bed94b7-d5da-4c5b-a812-25ecbb1601a6",
   "metadata": {},
   "source": [
    "# Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603889ff-e355-4c9e-929a-45e8150aa0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759ae117-0aa2-4c09-b5bd-7ce1e106ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd511c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca531938",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1839e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c527ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9fcee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchainhub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef23fe7-5c16-4f30-97e4-b679c75e716d",
   "metadata": {},
   "source": [
    "## Load OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77f69144-98d1-46a1-94be-8eea00065278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "OPENAI_API_KEY=os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafecdae-eaf9-471f-b69d-9b1c3ac0b9d2",
   "metadata": {},
   "source": [
    "## Load vector database from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0788aef1-0fe8-4205-ba3d-741bb5cf392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "db = FAISS.load_local(\"../faiss_index\", \n",
    "                      OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY, model=\"text-embedding-3-small\"), \n",
    "                      allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b7e3f2-eaba-4fa1-aced-d79431959cd9",
   "metadata": {},
   "source": [
    "## Configure retriever\n",
    "### Use the similarity search capabilities of a vector store to facilitate retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ec80ca7-918a-4898-b64d-4cee56d8141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3536c8-60fc-40c1-8265-2249a839db08",
   "metadata": {},
   "source": [
    "## Configure LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72e8727d-0efe-495d-b896-fcb3ca9d23ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#initialize the LLM we'll use - OpenAI GPT 3.5 Turbo\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc0fd64-aa2e-46fe-a2c6-a0b8ca109d76",
   "metadata": {},
   "source": [
    "## Define prompt with conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "732ea316-19cb-435f-b822-fb0647925980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "system_prompt = \"\"\"Given the chat history and a recent user question \\\n",
    "generate a new standalone question \\\n",
    "that can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed or otherwise return it as is.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retriever_with_history = create_history_aware_retriever(\n",
    "    llm, retriever, prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05940ef-89cd-4cc5-86e3-9a27f00f94a9",
   "metadata": {},
   "source": [
    "## Perform question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c79f88f-5924-4f52-ab0e-3825e16b2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\\n",
    "Use the following pieces of retrieved context to answer the question. \\\n",
    "If you don't know the answer, just say that you don't know. \\\n",
    "Use three sentences maximum and keep the answer concise.\\\n",
    "\n",
    "{context}\"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(retriever_with_history, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b0088c4-b593-404e-a9d5-36649862efe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aetherfloris Ventus is a celestial plant with petals lighter than air itself, appearing to float freely, nurtured by the whispers of the winds and clouds. Its stem is nearly invisible but surprisingly strong, leading the petals in a delicate dance with the breeze. The plant's essence, captured in rare vials, is believed to bestow the gift of lightness upon those who partake, freeing the mind and encouraging dreams to take flight.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "question = \"What is Aetherfloris Ventus?\"\n",
    "\n",
    "ai_msg_1 = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "\n",
    "chat_history.extend([HumanMessage(content=question), ai_msg_1[\"answer\"]])\n",
    "\n",
    "print(ai_msg_1[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b75d4d60-4b6b-49c6-a876-0a98bb2fbf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A single drop of Aetherfloris Ventus is said to lift the spirits, freeing the mind from earthly burdens and encouraging thoughts to soar. It induces a sense of lightness, both in the body and mind, allowing dreams to take flight and inspiring a feeling of weightlessness. The true nature of Aetherfloris Ventus remains a mystery, challenging even dedicated seekers to uncover its secrets.\n"
     ]
    }
   ],
   "source": [
    "second_question = \"What does a single drop of it do?\"\n",
    "\n",
    "ai_msg_2 = rag_chain.invoke({\"input\": second_question, \"chat_history\": chat_history})\n",
    "print(ai_msg_2[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67bfb493-0c2c-454d-8328-b83aed28406c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noctis Umbraherba is a dark, shadowy plant that thrives in the absence of light, with leaves absorbing darkness instead of sunlight. In contrast, Aetherfloris Ventus is a celestial plant with petals lighter than air, appearing to float freely and nurtured by the whispers of the winds and clouds. While Noctis Umbraherba is shrouded in mystery and thrives in darkness, Aetherfloris Ventus embodies the essence of lightness and freedom, reflecting a celestial beauty that captivates with its delicate presence.\n"
     ]
    }
   ],
   "source": [
    "third_question = \"How does it compare to Noctis Umbraherba?\"\n",
    "ai_msg_3 = rag_chain.invoke({\"input\": third_question, \"chat_history\": chat_history})\n",
    "print(ai_msg_3[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2b60c6b-57bc-44da-9706-0060095635e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, the Biological section of the Voynich Manuscript is significant as it provides intricate anatomical details of mythical beings, possibly reflecting ancient medical knowledge and alchemical practices. The annotated diagrams offer insights into the functions of fantastical organs and systems, possibly used in medicinal or alchemical preparations. These illustrations blend scientific observation with imaginative speculation, inviting further research into how ancient civilizations perceived biology and the body.\n"
     ]
    }
   ],
   "source": [
    "fourth_question = \"Do you think the Biological section of the Voynich Manuscript is important?\"\n",
    "ai_msg_4 = rag_chain.invoke({\"input\": fourth_question, \"chat_history\": chat_history})\n",
    "print(ai_msg_4[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
